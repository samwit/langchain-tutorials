{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRYSu48huSUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71bc0be9-8134-4d8c-b824-b1179a0843e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install langchain openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "dNA4TsHpu6OM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show langchain"
      ],
      "metadata": {
        "id": "J-KFB7J_u_3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d2b84f3-d1e8-4b2b-a08c-39ddf116834a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: langchain\n",
            "Version: 0.0.252\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: https://www.github.com/hwchase17/langchain\n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aiohttp, async-timeout, dataclasses-json, langsmith, numexpr, numpy, openapi-schema-pydantic, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RCI Chain with ChatModel"
      ],
      "metadata": {
        "id": "HqwsGJDhvAQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi Chain"
      ],
      "metadata": {
        "id": "1T4xsy4ND2av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "from langchain.schema.output_parser import StrOutputParser"
      ],
      "metadata": {
        "id": "ezZ5D55uD-Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0\n",
        "    )"
      ],
      "metadata": {
        "id": "P_Vz09usvqhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"tell me an intersting fact about {subject}\"\n",
        "    )\n",
        "\n",
        "reverse_prompt = ChatPromptTemplate.from_template(\n",
        "    \"based on this interesting fact which is chunked down from a meta subject:\\n\\n {interesting_fact}\\n\\n Recover what the meta subject is\\n Subject:\"\n",
        "    )"
      ],
      "metadata": {
        "id": "Z6HVNGkvv9-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "UoeILxMtwS-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({\"subject\": \"Elvis\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "cm8y8Ll4wJMH",
        "outputId": "8f647e6e-158d-4eeb-b3f1-793191c07e43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'One interesting fact about Elvis Presley is that he was a black belt in karate. He began studying martial arts in the 1950s and eventually earned his black belt in 1960. Elvis was passionate about karate and even incorporated some of the moves into his stage performances. He often practiced martial arts as a way to stay fit and maintain discipline in his life.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# full chain doesn't work\n",
        "full_chain = prompt | model | StrOutputParser() | reverse_prompt | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "mYGOba4-EiLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "\n",
        "langchain.debug = True"
      ],
      "metadata": {
        "id": "jRzytVdiEwX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_chain.invoke({\"subject\": \"Elvis\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WGfhcc2-E0lZ",
        "outputId": "fbe2072d-16fc-4ed2-ac5e-5073ef31e9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"subject\": \"Elvis\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:prompt:ChatPromptTemplate] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"subject\": \"Elvis\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:prompt:ChatPromptTemplate] [1.065ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 3:llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: tell me an intersting fact about Elvis\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 3:llm:ChatOpenAI] [2.84s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"One interesting fact about Elvis Presley is that he was a black belt in karate. He began studying martial arts in the 1950s and eventually earned his black belt in 1960. Elvis was passionate about karate and even incorporated some of the moves into his performances. He often practiced with his friends and bodyguards, and even had a custom-made karate uniform with his name embroidered on it.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\"\n",
            "        },\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"One interesting fact about Elvis Presley is that he was a black belt in karate. He began studying martial arts in the 1950s and eventually earned his black belt in 1960. Elvis was passionate about karate and even incorporated some of the moves into his performances. He often practiced with his friends and bodyguards, and even had a custom-made karate uniform with his name embroidered on it.\",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"prompt_tokens\": 16,\n",
            "      \"completion_tokens\": 83,\n",
            "      \"total_tokens\": 99\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 4:parser:StrOutputParser] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 4:parser:StrOutputParser] [0.252ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"One interesting fact about Elvis Presley is that he was a black belt in karate. He began studying martial arts in the 1950s and eventually earned his black belt in 1960. Elvis was passionate about karate and even incorporated some of the moves into his performances. He often practiced with his friends and bodyguards, and even had a custom-made karate uniform with his name embroidered on it.\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 5:prompt:ChatPromptTemplate] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"One interesting fact about Elvis Presley is that he was a black belt in karate. He began studying martial arts in the 1950s and eventually earned his black belt in 1960. Elvis was passionate about karate and even incorporated some of the moves into his performances. He often practiced with his friends and bodyguards, and even had a custom-made karate uniform with his name embroidered on it.\"\n",
            "}\n",
            "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 5:prompt:ChatPromptTemplate] [0.303ms] Chain run errored with error:\n",
            "\u001b[0m\"TypeError('langchain.prompts.chat.BaseChatPromptTemplate.format_prompt() argument after ** must be a mapping, not str')\"\n",
            "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [2.85s] Chain run errored with error:\n",
            "\u001b[0m\"TypeError('langchain.prompts.chat.BaseChatPromptTemplate.format_prompt() argument after ** must be a mapping, not str')\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-1f0af0acc9cc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"subject\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Elvis\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/schema/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                 input = step.invoke(\n\u001b[0m\u001b[1;32m    274\u001b[0m                     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                     \u001b[0;31m# mark each step as a child run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/schema/prompt_template.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRunnableConfig\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPromptValue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         return self._call_with_config(\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;32mlambda\u001b[0m \u001b[0minner_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/schema/runnable.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input, config, run_type)\u001b[0m\n\u001b[1;32m    180\u001b[0m         )\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/schema/prompt_template.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRunnableConfig\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPromptValue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         return self._call_with_config(\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mlambda\u001b[0m \u001b[0minner_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: langchain.prompts.chat.BaseChatPromptTemplate.format_prompt() argument after ** must be a mapping, not str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain1 = prompt | model | StrOutputParser()\n",
        "\n",
        "chain2 = {\"interesting_fact\": chain1} | reverse_prompt | model | StrOutputParser()\n"
      ],
      "metadata": {
        "id": "K82XYV2zGnWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain2.invoke({\"subject\": \"elvis\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jSVepkyWG0rV",
        "outputId": "dc71faa6-79f9-4ce0-c621-9975dafa796d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"subject\": \"elvis\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": {\n",
            "    \"subject\": \"elvis\"\n",
            "  }\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"subject\": \"elvis\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 4:prompt:ChatPromptTemplate] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"subject\": \"elvis\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 4:prompt:ChatPromptTemplate] [1.426ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 5:llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: tell me an intersting fact about elvis\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 5:llm:ChatOpenAI] [2.87s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"One interesting fact about Elvis Presley is that he was a black belt in karate. He began studying martial arts in the 1950s and eventually earned his black belt in 1960. Elvis was passionate about karate and even incorporated some of the moves into his performances. He often practiced with his friends and bodyguards, and even had a custom-made karate uniform with his name embroidered on it.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\"\n",
            "        },\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"One interesting fact about Elvis Presley is that he was a black belt in karate. He began studying martial arts in the 1950s and eventually earned his black belt in 1960. Elvis was passionate about karate and even incorporated some of the moves into his performances. He often practiced with his friends and bodyguards, and even had a custom-made karate uniform with his name embroidered on it.\",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"prompt_tokens\": 17,\n",
            "      \"completion_tokens\": 83,\n",
            "      \"total_tokens\": 100\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 6:parser:StrOutputParser] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 6:parser:StrOutputParser] [0.259ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"One interesting fact about Elvis Presley is that he was a black belt in karate. He began studying martial arts in the 1950s and eventually earned his black belt in 1960. Elvis was passionate about karate and even incorporated some of the moves into his performances. He often practiced with his friends and bodyguards, and even had a custom-made karate uniform with his name embroidered on it.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence] [2.87s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"One interesting fact about Elvis Presley is that he was a black belt in karate. He began studying martial arts in the 1950s and eventually earned his black belt in 1960. Elvis was passionate about karate and even incorporated some of the moves into his performances. He often practiced with his friends and bodyguards, and even had a custom-made karate uniform with his name embroidered on it.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap] [2.88s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"interesting_fact\": \"One interesting fact about Elvis Presley is that he was a black belt in karate. He began studying martial arts in the 1950s and eventually earned his black belt in 1960. Elvis was passionate about karate and even incorporated some of the moves into his performances. He often practiced with his friends and bodyguards, and even had a custom-made karate uniform with his name embroidered on it.\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 7:prompt:ChatPromptTemplate] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"interesting_fact\": \"One interesting fact about Elvis Presley is that he was a black belt in karate. He began studying martial arts in the 1950s and eventually earned his black belt in 1960. Elvis was passionate about karate and even incorporated some of the moves into his performances. He often practiced with his friends and bodyguards, and even had a custom-made karate uniform with his name embroidered on it.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 7:prompt:ChatPromptTemplate] [0.384ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 8:llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Human: based on this interesting fact which is chunked down from a meta subject:\\n\\n One interesting fact about Elvis Presley is that he was a black belt in karate. He began studying martial arts in the 1950s and eventually earned his black belt in 1960. Elvis was passionate about karate and even incorporated some of the moves into his performances. He often practiced with his friends and bodyguards, and even had a custom-made karate uniform with his name embroidered on it.\\n\\n Recover what the meta subject is\\n Subject:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 8:llm:ChatOpenAI] [632.385ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"Elvis Presley's interest and proficiency in karate.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\"\n",
            "        },\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"Elvis Presley's interest and proficiency in karate.\",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"prompt_tokens\": 114,\n",
            "      \"completion_tokens\": 12,\n",
            "      \"total_tokens\": 126\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 9:parser:StrOutputParser] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 9:parser:StrOutputParser] [0.265ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"Elvis Presley's interest and proficiency in karate.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [3.52s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"Elvis Presley's interest and proficiency in karate.\"\n",
            "}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Elvis Presley's interest and proficiency in karate.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# As LCEL"
      ],
      "metadata": {
        "id": "jqDy4FroigDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "langchain.debug = False"
      ],
      "metadata": {
        "id": "cUOH6rVBiNOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n"
      ],
      "metadata": {
        "id": "8PrgOsByPHZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template=\"You are a helpful assistant that imparts wisdom and guides people with accurate answers.\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "human_template=\"{question}\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])"
      ],
      "metadata": {
        "id": "Nb1gtx1vhopk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain1 = chat_prompt | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "Z1vbc_tShv3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_question = \"Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\""
      ],
      "metadata": {
        "id": "TQxR1btKhv4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_answer = chain1.invoke({\"question\": initial_question})\n",
        "initial_answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6561eb6f-f1f0-417e-e549-8c8cc97189c5",
        "id": "Qnczl4rWhv4J"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Roger initially has 5 tennis balls. He buys 2 cans of tennis balls, and each can has 3 tennis balls. So, the total number of tennis balls he buys is 2 cans * 3 tennis balls/can = 6 tennis balls. \\n\\nTherefore, Roger now has a total of 5 tennis balls + 6 tennis balls = 11 tennis balls.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_initial_ai_answer = \"\"\"Roger initially has 5 tennis balls. Each can of tennis balls contains 3 tennis balls, and he bought 2 cans, so he has 2 x 3 = 6 additional tennis balls.\n",
        "Therefore, the total number of tennis balls Roger has now is 5 + 4 = 9.\"\"\""
      ],
      "metadata": {
        "id": "dt4wOS1wPDDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2 - Critique  "
      ],
      "metadata": {
        "id": "LdifZhmeh5fK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template=\"You are a helpful assistant that looks at answers and finds what is wrong with them based on the original question given.\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "human_template=\"### Question:\\n\\n{question}\\n\\n ###Answer Given:{initial_answer}\\n\\n Review your previous answer and find problems with your answer\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
      ],
      "metadata": {
        "id": "Lyn5cvz2gS2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rc_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])"
      ],
      "metadata": {
        "id": "8Ud512H8gS2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain2 = rc_prompt | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "VSz9eWU6gagJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "constructive_criticism = chain2.invoke({\"question\": initial_question, \"initial_answer\":fake_initial_ai_answer})\n",
        "constructive_criticism"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "xyrzdgNbg-u6",
        "outputId": "08055a11-4e0b-4806-f704-8dd451fbe0b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The problem with the given answer is that it incorrectly calculates the total number of tennis balls Roger has now. The answer states that Roger has 5 tennis balls initially, and then adds 4 (2 x 3) additional tennis balls from the cans he bought. However, the correct calculation should be 5 + (2 x 3) = 11. Therefore, the correct answer is that Roger has 11 tennis balls now.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3 - The Improvement"
      ],
      "metadata": {
        "id": "ThJCqWYXi5To"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template=\"You are a helpful assistant that reviews answers and critiques based on the original question given and write a new improved final answer.\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "human_template=\"### Question:\\n\\n{question}\\n\\n ###Answer Given:{initial_answer}\\n\\n \\\n",
        "###Constructive Criticism:{constructive_criticism}\\n\\n Based on the problems you found, improve your answer.\\n\\n### Final Answer:\"\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
      ],
      "metadata": {
        "id": "GF9xkoAJjIZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "improvement_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])"
      ],
      "metadata": {
        "id": "kUVYEp0pjIZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain3 = improvement_prompt | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "IUGNqQg_l0st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_result = chain3.invoke({\"question\": initial_question,\n",
        "                              \"initial_answer\":fake_initial_ai_answer,\n",
        "                              \"constructive_criticism\": constructive_criticism})\n",
        "\n",
        "final_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "yUkfpDedl975",
        "outputId": "2c277e29-9d68-4820-d4b4-c87ec3db927d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Roger initially has 5 tennis balls. He buys 2 cans of tennis balls, and each can contains 3 tennis balls. Therefore, he has 2 x 3 = 6 additional tennis balls. Adding this to the initial 5 tennis balls, Roger now has a total of 5 + 6 = 11 tennis balls.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combined Chain"
      ],
      "metadata": {
        "id": "xQPHAp5emT9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter"
      ],
      "metadata": {
        "id": "v7coUHRTrXW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "chain1 = chat_prompt | model | StrOutputParser()\n",
        "\n",
        "critque_chain = {\"question\": itemgetter(\"question\"),\n",
        "                 \"initial_answer\": chain1 } | rc_prompt | model | StrOutputParser()\n",
        "\n",
        "chain3 = {\"question\": itemgetter(\"question\"),\n",
        "          \"initial_answer\": chain1,\n",
        "          \"constructive_criticism\": critque_chain} | improvement_prompt | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "QhXNxN1ZmLqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain3.invoke({\"question\":\"Write an sms message to say I am tired\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "JvTj9xb0rLWG",
        "outputId": "806c63ff-69de-4325-d8fc-5167c8ef67ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hey [Recipient's Name], just wanted to shoot you a quick message to let you know that I'm feeling exhausted today. I could really use some rest and relaxation to recharge. Take care!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "langchain.debug = True"
      ],
      "metadata": {
        "id": "ihFvgx2ksWtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain3.invoke({\"question\":\"Write an sms message to say I am tired\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "z_FiZIqBstKY",
        "outputId": "97124c46-5fb5-43dd-a1d0-f80ec9aacf6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": {\n",
            "    \"question\": \"Write an sms message to say I am tired\"\n",
            "  }\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\"\n",
            "}\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\"\n",
            "}\n",
            "\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 4:prompt:ChatPromptTemplate] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableLambda] [4.859ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"Write an sms message to say I am tired\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 4:prompt:ChatPromptTemplate] [1.24ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\"\n",
            "}\n",
            "\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 5:chain:RunnableMap] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": {\n",
            "    \"question\": \"Write an sms message to say I am tired\"\n",
            "  }\n",
            "}\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 5:llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful assistant that imparts wisdom and guides people with accurate answers.\\nHuman: Write an sms message to say I am tired\"\n",
            "  ]\n",
            "}\n",
            "\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 5:chain:RunnableMap > 6:chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 5:chain:RunnableMap > 6:chain:RunnableLambda] [0.8140000000000001ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"Write an sms message to say I am tired\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 5:chain:RunnableMap > 7:chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 5:chain:RunnableMap > 7:chain:RunnableSequence > 8:prompt:ChatPromptTemplate] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 5:chain:RunnableMap > 7:chain:RunnableSequence > 8:prompt:ChatPromptTemplate] [0.309ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 5:chain:RunnableMap > 7:chain:RunnableSequence > 9:llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful assistant that imparts wisdom and guides people with accurate answers.\\nHuman: Write an sms message to say I am tired\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 5:chain:RunnableMap > 7:chain:RunnableSequence > 9:llm:ChatOpenAI] [1.51s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"Hey [Recipient's Name], just wanted to let you know that I'm feeling pretty tired today. Need some rest and recharge. Take care!\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\"\n",
            "        },\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"Hey [Recipient's Name], just wanted to let you know that I'm feeling pretty tired today. Need some rest and recharge. Take care!\",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"prompt_tokens\": 36,\n",
            "      \"completion_tokens\": 29,\n",
            "      \"total_tokens\": 65\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 5:chain:RunnableMap > 7:chain:RunnableSequence > 10:parser:StrOutputParser] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 5:chain:RunnableMap > 7:chain:RunnableSequence > 10:parser:StrOutputParser] [0.42000000000000004ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"Hey [Recipient's Name], just wanted to let you know that I'm feeling pretty tired today. Need some rest and recharge. Take care!\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 5:chain:RunnableMap > 7:chain:RunnableSequence] [1.51s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"Hey [Recipient's Name], just wanted to let you know that I'm feeling pretty tired today. Need some rest and recharge. Take care!\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 5:chain:RunnableMap] [1.52s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\",\n",
            "  \"initial_answer\": \"Hey [Recipient's Name], just wanted to let you know that I'm feeling pretty tired today. Need some rest and recharge. Take care!\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 11:prompt:ChatPromptTemplate] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\",\n",
            "  \"initial_answer\": \"Hey [Recipient's Name], just wanted to let you know that I'm feeling pretty tired today. Need some rest and recharge. Take care!\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 11:prompt:ChatPromptTemplate] [0.512ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 12:llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful assistant that looks at answers and finds what is wrong with them based on the original question given.\\nHuman: ### Question:\\n\\nWrite an sms message to say I am tired\\n\\n ###Answer Given:Hey [Recipient's Name], just wanted to let you know that I'm feeling pretty tired today. Need some rest and recharge. Take care!\\n\\n Review your previous answer and find problems with your answer\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 5:llm:ChatOpenAI] [1.72s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"Hey [Recipient's Name], just wanted to let you know that I'm feeling pretty tired right now. Need some rest and recharge. Take care!\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\"\n",
            "        },\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"Hey [Recipient's Name], just wanted to let you know that I'm feeling pretty tired right now. Need some rest and recharge. Take care!\",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"prompt_tokens\": 36,\n",
            "      \"completion_tokens\": 30,\n",
            "      \"total_tokens\": 66\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 6:parser:StrOutputParser] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence > 6:parser:StrOutputParser] [0.34099999999999997ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"Hey [Recipient's Name], just wanted to let you know that I'm feeling pretty tired right now. Need some rest and recharge. Take care!\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 3:chain:RunnableSequence] [1.73s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"Hey [Recipient's Name], just wanted to let you know that I'm feeling pretty tired right now. Need some rest and recharge. Take care!\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 12:llm:ChatOpenAI] [1.26s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"There are no apparent problems with the given answer. It accurately conveys the message of being tired and the need for rest.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\"\n",
            "        },\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"There are no apparent problems with the given answer. It accurately conveys the message of being tired and the need for rest.\",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"prompt_tokens\": 90,\n",
            "      \"completion_tokens\": 25,\n",
            "      \"total_tokens\": 115\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 13:parser:StrOutputParser] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence > 13:parser:StrOutputParser] [0.379ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"There are no apparent problems with the given answer. It accurately conveys the message of being tired and the need for rest.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap > 4:chain:RunnableSequence] [2.78s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"There are no apparent problems with the given answer. It accurately conveys the message of being tired and the need for rest.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:chain:RunnableMap] [2.80s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\",\n",
            "  \"initial_answer\": \"Hey [Recipient's Name], just wanted to let you know that I'm feeling pretty tired right now. Need some rest and recharge. Take care!\",\n",
            "  \"constructive_criticism\": \"There are no apparent problems with the given answer. It accurately conveys the message of being tired and the need for rest.\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 14:prompt:ChatPromptTemplate] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"Write an sms message to say I am tired\",\n",
            "  \"initial_answer\": \"Hey [Recipient's Name], just wanted to let you know that I'm feeling pretty tired right now. Need some rest and recharge. Take care!\",\n",
            "  \"constructive_criticism\": \"There are no apparent problems with the given answer. It accurately conveys the message of being tired and the need for rest.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 14:prompt:ChatPromptTemplate] [0.85ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 15:llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful assistant that reviews answers and critiques based on the original question given and write a new improved final answer.\\nHuman: ### Question:\\n\\nWrite an sms message to say I am tired\\n\\n ###Answer Given:Hey [Recipient's Name], just wanted to let you know that I'm feeling pretty tired right now. Need some rest and recharge. Take care!\\n\\n ###Constructive Criticism:There are no apparent problems with the given answer. It accurately conveys the message of being tired and the need for rest.\\n\\n Based on the problems you found, improve your answer.\\n\\n### Final Answer:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 15:llm:ChatOpenAI] [2.40s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"Hey [Recipient's Name], just wanted to shoot you a quick message to let you know that I am absolutely exhausted right now. I've been running on fumes and desperately need some rest and relaxation. Take care and catch up with you soon!\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\"\n",
            "        },\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessage\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"Hey [Recipient's Name], just wanted to shoot you a quick message to let you know that I am absolutely exhausted right now. I've been running on fumes and desperately need some rest and relaxation. Take care and catch up with you soon!\",\n",
            "            \"additional_kwargs\": {}\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"prompt_tokens\": 128,\n",
            "      \"completion_tokens\": 50,\n",
            "      \"total_tokens\": 178\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 16:parser:StrOutputParser] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 16:parser:StrOutputParser] [0.268ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"Hey [Recipient's Name], just wanted to shoot you a quick message to let you know that I am absolutely exhausted right now. I've been running on fumes and desperately need some rest and relaxation. Take care and catch up with you soon!\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [5.21s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"Hey [Recipient's Name], just wanted to shoot you a quick message to let you know that I am absolutely exhausted right now. I've been running on fumes and desperately need some rest and relaxation. Take care and catch up with you soon!\"\n",
            "}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hey [Recipient's Name], just wanted to shoot you a quick message to let you know that I am absolutely exhausted right now. I've been running on fumes and desperately need some rest and relaxation. Take care and catch up with you soon!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fCZO8y8gsvcR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}